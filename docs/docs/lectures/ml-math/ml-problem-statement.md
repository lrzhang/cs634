---
title: ML Problem Statement
---

## The learning problem 
Let us start with a classic formal definition of the learning problem.

![learning-problem](images/enhanced-vapnik-learning-problem.svg)

*Vapnik's formulation of the learning problem (enhanced)*

The description below is taken from Vadimir Vapnik's classic book [Statistical Learing Theory](https://www.amazon.com/Statistical-Learning-Theory-Vladimir-Vapnik/dp/0471030031), albeit with some enhancements on terminology to make it more in line with this course. 

The generator is a source of situations that determines the environment in which the target function (he calls it supervisor) and the learning algorithm act.  Here we consider the simplest environment: the data generator generates the vectors $\mathbf{x} \in \mathcal{X}$ independently and identically distributed (i.i.d.) according to some unknown (but fixed) probability distribution function $F(x)$.

These vectors are inputs to the target function (or operator); the target operator returns the output values $\mathbf{y}$. The target operator which transforms the vectors $\mathbf{x}$ into values y,  is **unknown** but we know that it  exists and does not change.

The learning algorithm observes the training dataset,

$$\{ (\mathbf{x}_1, y_1), \dots, (\mathbf{x}_m, y_m) \}$$

which contain input vectors $\mathbf{x}$ and the target response $\mathbf{y}$. During this period, the learning algorithm constructs some operator which will he used for prediction of the supervisor's answer $y_i$ on any specific vector $\mathbf{x}_i$  generated by the generator. The goal of the learning algorithm is  to construct an appropriate **approximation** of the target function - we will call this a hypothesis. The hypothesis can be iteratively constructed so the final hypothesis is the one that is used to produce the label $\hat{y}$. 

To be a mathematically correct, this general scheme of learning from examples needs some clarification. First of all,  we have to describe what kind of operators are used by the target function. In this book. we suppose that the target function returns the output $\mathbf{y}$ on the vector $\mathbf{x}$ according to  a conditional distribution function $F(\mathbf{y} | \mathbf{x})$ (this includes the case when the supervisor uses some function $\mathbf{y} = f(\mathbf{x}))$.

The learning algorithm observes the training set which is drawn randomly and independently according to  a joint distribution function $F(\mathbf{x} , \mathbf{y}) = F(\mathbf{x}) F(\mathbf{y} | \mathbf{x})$. Recall that we do not know this function but we do know that it  exists. Using this training set, the learning algorithm constructs an approximation to the unknown function.

## Regularization or Shrinkage
Now that we have introduced somewhat more formally the learning problem and its notation lets us study a simple but instructive regression problem from Chapter 1 of Bishop's book that is known in the statistics literature as *shrinkage*. Note that in many figures below the label is denoted as $t$ rather than $y$ as used in the equations below.

Suppose that we are given the training set  $\mathbf{x} = \{x_1,...,x_m\}$ together with their labels, the vectors $\mathbf{y}$. We need to construct a model such that a *suitably chosen* loss function is minimized for a **different** set of input data, the so-called test set. The ability to correctly *predict* when observing the test set, is called **generalization**.

![Training dataset and Target Unknown Function](images/Figure1.2.png)
*Training Dataset (m=10) for the Regression Model. The green curve is the uknown target function.*

Since the output $y$ is a continuous variable then the supervised learning problem is called a regression problem (otherwise its a classification problem). The dataset is generated (in data scienece these datasets are called *synthetic*) by the function $sin(2 \pi x) + n$ where $x$ is a uniformly distributed random variable and $n$ is $N(\mu=0.0, \sigma^2=0.3)$. This target function is **completely unknown** to us - we just mention it here for completeness.  

Let us now pick the hypothesis set that correspond to polynomials of the following form,

$$g(\mathbf{w},x) = w_0 + w_1x + w_2 x^2 + ... + w_M x^M$$

Our job is to find $\mathbf{w}$ such that the polynomial above fits the data we are given - as we will see there are multiple hypothesis that can satisfy this requirement. To gauge our investigation, we need to define a metric, an error or loss function in fact, that is also a common metric in regression problems of this nature. This is the Mean Squared Error function. 

$$L(\mathbf{w}) = \frac{1}{2} \sum_{i=1}^m \{g(\mathbf{w},x_i)-t_i)\}^2$$

![Loss Function](images/Figure1.3.png)
*The loss function chosen for this regression problem, corresponds to the sum of the squares of the displacements of each data point and our hypothesis. The sum of squares in the case of Gaussian errors gives raise to an (unbiased) Maximum Likelihood estimate of the model parameters. Contrast this to sum of absolute differences.*

Now our job has become to choose two things: the weight vector $\mathbf{w^*}$ *and* $M$ the order of the polynomial. **Both** define our hypothesis.  If you think about it, the order $M$ defines the model complexity in the sense that the larger $M$ becomes the more the number of weights we need to estimate and store. Obviously this is a trivial example and storage is not a concern here but treat this example as instructive for that it applies in many far for complicated settings. 

![Loss Function](images/Figure1.4a.png)
![Loss Function](images/Figure1.4b.png)
![Loss Function](images/Figure1.4c.png)
![Loss Function](images/Figure1.4d.png)

Obviously you can reduce the training error to almost zero by selecting a model that is complicated enough (M=9) to perfectly fit the training data (if m is small).  

![Loss Function](images/Figure1.5.png)

But this is not what you want to do. Because when met with test data, the model will perform far worse than a less complicated model that is closer to the true model (e.g. M=3). This is a central observation in statistical learning called **overfitting**. In addition, you may not have the time to iterate over M (very important in online learning settings). 

To avoid overfitting we have multiple strategies. One straightforward one is evident by observing the wild oscillations of the $\mathbf{w}$ elements as the model complexity increases. We can penalize such oscillations by introducing the $l_2$ norm of $\mathbf{w}$ in our loss function.

$$L(\mathbf{w}) = \frac{1}{2} \sum_{i=1}^m \{g(\mathbf{w},x_i)-t_i)\}^2 + \frac{\lambda}{2} ||\mathbf{w}||^2$$

This type of solution is called **regularization** and because we effectively shrink the weight dynamic range it is also called in statistics shrinkage or ridge regression. We have introduced a new parameter $\lambda$ that regulates the relative importance of the penalty term as compared to the MSE. This parameter together with the polynomial order is what we call *hyperparameters* and we need to optimize them as both are needed for the determination of our final hypothesis $g$. 

The graph below show the results of each search iteration on the $\lambda$ hyperparameter.

![Loss Function](images/Figure1.8.png)

Now that we have concluded the treatment of some elementary concepts, let us use them in a [data mining problem](../ml-frameworks/zillow-app).